<!DOCTYPE html>
<html lang="en-us">
<head>
  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  
  <meta name="generator" content="Hugo 0.49" />
  <meta name="author" content="Check King">

  
  <link rel="stylesheet" href="//cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.min.css">
  <link rel="stylesheet" href="//fonts.googleapis.com/css?family=Merriweather:400,700%7cOpen&#43;Sans:400,400italic,700%7cRoboto&#43;Mono%25!%28EXTRA%20*hugolib.PageOutput=Page%28/post%29%29">
  <link rel="stylesheet" href="/styles.css">
  

  

  
  <link rel="alternate" href="https://checkking.github.io/post/index.xml" type="application/rss+xml" title="Check King&#39;s Blog">
  <link rel="feed" href="https://checkking.github.io/post/index.xml" type="application/rss+xml" title="Check King&#39;s Blog">
  

  <link rel="apple-touch-icon" sizes="180x180" href="/img/favicon/apple-touch-icon.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/img/favicon/favicon-32x32.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/img/favicon/favicon-16x16.png">
  <link rel="manifest" href="/img/favicon/site.webmanifest">
  <link rel="mask-icon" href="/safari-pinned-tab.svg" color="#5bbad5">
  <meta name="msapplication-TileColor" content="#da532c">
  <meta name="theme-color" content="#ffffff">

  <link rel="manifest" href="/site.webmanifest">
  <link rel="icon" type="image/png" href="/img/icon.png">
  <link rel="apple-touch-icon" type="image/png" href="/img/icon-192.png">

  <link rel="canonical" href="https://checkking.github.io/post/">

  <meta property="twitter:card" content="summary_large_image">
  
  <meta property="twitter:site" content="@">
  <meta property="twitter:creator" content="@">
  
  <meta property="og:site_name" content="Check King&#39;s Blog">
  <meta property="og:url" content="https://checkking.github.io/post/">
  <meta property="og:title" content="Posts | Check King&#39;s Blog">
  <meta property="og:locale" content="en-us">
  
  <meta property="og:updated_time" content="2017-04-30T21:07:16&#43;08:00">
  

  <title>Posts | Check King&#39;s Blog</title>

  

</head>
<body>

<style type="text/css">

.masthead-hero {
  background-image: url("https://checkking.github.io/img/hero.jpg");
}
</style>

<div class="masthead-hero"></div>


  <h1>Posts</h1>

  

  
  
  <div>
    <h2><a href="https://checkking.github.io/post/arch/sample/">谈谈抽样试验</a></h2>
    <div class="post-style">
      
      背景 对于一些重要的产品，开发出的新功能往往需要真实流量进行验证才能知道这个功能带来的收益是好还是坏，比如图搜变现的策略rd想要在图搜wise端出游戏的一个广告banner，点击这个广告banner，会跳到一个下载中间页，我们最终的目的是要提高下载量，这就要评估一下哪种下载中间页会提高下载量，当然还有一些其他的评估指标。因此需要从整个流量中抽取两个小部分流量来做对比实验。怎么去分配流量，让不同流量走不同的逻辑就是抽样框架的主要任务。 还有FE开发了一种新的广告样式，需要确认这种样式会不会提高CTR。这些新策略，新样式的上线，都需要灰度发布，也就是小流量实验。
我们的广告模块也实现了一个实验框架，用于灰度发布，我分析一下这个实验框架的细节。
实验框架的整体流程 实验用户通过抽样平台上创建抽样试验，比如这个抽样试验要对流量按照uid进行划分，实验组需要流量为1%, 对照组所需流量为1%，如果现有所有流量层有按照cuid划分的，并且这一层上剩余流量充足，则在这一层上选取流量区间分配给实验组和对照组。
则可以将流量区间1000~1099分配给实验组，并创建一个新的sid加入配置，将1100~1199分配给对照组，并创建一个新的sid加入配置。
流量分配好之后，就可以在这个流量下面创建一些策略变量，比如在实验组中这个变量值为x,在对照组中，这个变量值为y（变量需要指定模块）。还可以加入一些过滤条件，对流量进行过滤。比如比如query不能在某个此表中。
实验创建好，并通过审核，准备上线。就会生成两类配置。一类是广告入口模块（midway）所使用的流量划分配置，模块根据这个配置，对请求打上sid列表。传递给下游模块。另外一类配置是各个模块使用的抽样变量配置。程序在运行的时候根据不同sid取得不同的变量值，走不同的逻辑。
配置是通过一个配置配送模块进行的, 各个模块热加载配置。
具体打sid的过程 midway拿到流量分配配置后，解析配置，layermanager将按层解析配置，按层管理各个layer, layer中包含各个抽样节点，比如sid 999的流量区间为start=0, end=999
而且每层的sid都是按照start排序的。后续一个请求hash得到的一个整数就可以按照二分查找。
一个请求过来之后，就会一层一层地去匹配sid，每层最多匹配一个。
查找变量过程 下游模块加载抽样变量配置，热加载，按照变量名组织:
struct SampleParam { uint32_t sid,; void* val; } std::unordered_map&lt;std::string, SampleParam&gt; sample_variables.  当代码要用到抽样变量时，先到sample_variable中查找，如果不到，则用默认值。
为了统计和评估，在日志中加入sid, 这样可以统计pv,ctr等信息。
流量切分 流量划分的粒度为0.1%， 我们将全部流量划分成10000等份，这样全部流量就是0~9999。对输入进行随机hash计算，可以将流量打散在全流量中。 流量可以按照以下几种方式来划分： 1) 按IP来进行划分(地域)  2) 按UID进行划分 3) 按cookie进行划分 4) 按query进行划分
首先将key对应的字符串用creat_sign_murmur64函数转成64位的整数，然后对10000取模，得到一个0~10000之间的整数。整个整数再去和各个抽样进行匹配，如果在某个抽样区间，则将请求打上对应的sid。
实现流量的分层 100%的流量很容易被用完，加入每个实验都需要10%的流量，这样同时只能做10个实验。而且有些实验要求更多的流量，比如有些实验要求在特定query下才走什么要的策略，假如只抽取1%的流量，这样再用这个流量进行query过滤，那就太少了，因此这类实验往往要求很多的流量，比如30%。这样势必会造成流量不够用的情况。
因此需要进行流量分层，将100%的流量正交成16个全流量，从逻辑上将实验流量变成原来的16倍。正交的意思是指第一层的某段很小的1%流量能够均匀地分散到其他层的100%上，而不是集中在其他层的某一段。 正交层之间几乎没有相互影响：
假如有实验1，有实验组exp_a和对照组control_a，各占流量1%,在第一层，第二层中有实验2，有实验组exp_a，占流量2%。如果不正交的话，导致实验1和实验2流量重叠，一个请求要么全部中实验一和实验二，要么全不中。这样两个实验就可能会相互影响了（即使两个实验不互斥）。如果保证正交的话，第一层实验1的流量均匀的落到第二层，这样就只有极少一部分流量落到实验2中的流量。
如果实验1和实验2互斥，比如都要在一个广告位上出广告，这样实验一和实验二必须都在同一层。
分层的实现是为不同层的creat_sign_murmur64函数设置不同的初始化种子字符串实现的，在创建层的时候为每个层分配一个全局唯一的id，作为层的初始化seed。具体代码如下：
ErrorCode calc_sample_ratio(const boost::any &amp;any_value, const std::string &amp;seed, double &amp;sample_ratio) { std::string val; if (boost_any_to_str(any_value, val) !
      
    </div>
  </div>
  
  <div>
    <h2><a href="https://checkking.github.io/post/cs/link/">硬连接和软连接</a></h2>
    <div class="post-style">
      
      背景 项目的nginx日志太多了，需要迁移到其他磁盘，另外一个同学采用软链的方式迁移到其他磁盘上，这样不影响现有程序。对于软链和硬连接概念上还是有些模糊，所以总结一下，直接抄Quora上的一个通俗的回答.
What is the difference between a hard link and a soft link? Have you ever given a thought to what happens when you store a file on your hard disk?
I will show you.
Let’s create a file first.
touch myfile cat &gt; myfile Hello, world!  cat file should display this text:
cat myfile Hello, world!  Where do you think myfile is stored?
An obvious and correct answer is your hard drive.
      
    </div>
  </div>
  
  <div>
    <h2><a href="https://checkking.github.io/post/nginx/nginx7/">一个简易的debug库设计与实现</a></h2>
    <div class="post-style">
      
      背景 最近项目上线了广告Offer按照ecpm等排序策略功能，上线之后经常被pm骚扰，因为他经常想查看为什么一个offer没有展示等问题，每次都要帮他查看线上日志，过程很痛苦，占用了大把时间。必须要改变这种现状。
debug的用途 便于线上case追踪用，分析程序执行的每个环节。
设计要点  debug信息的层级关系  为了很好地阅读debug信息，必须将debug信息很好地组织起来，比如一个请求来了，在后台执行的时候需要经过好几步，stage1, stage2,state3,&hellip;,其中stage1中又有好几步，我们可以把这些信息按照树的结构组织起来：
{ &quot;request&quot;: { &quot;ip&quot;: &quot;180.92.201.3&quot;, &quot;uri&quot;: &quot;/api/offer&quot;, &quot;network&quot;: &quot;wifi&quot;, &quot;debugid&quot;: &quot;8782399662&quot; }, &quot;process&quot;: { &quot;stage_readOffers&quot;: [ { &quot;offer_id&quot;: &quot;3142&quot;, &quot;type&quot;: &quot;aio&quot;, &quot;flags&quot;: { &quot;d&quot;: 1, &quot;x&quot;: false, &quot;ne&quot;: -1 } }, { &quot;offer_id&quot;: &quot;3142&quot;, &quot;type&quot;: &quot;aio&quot;, &quot;flags&quot;: { &quot;d&quot;: 1, &quot;x&quot;: false, &quot;ne&quot;: -1 } }, &hellip; ], &quot;stage_filterOffers&quot;: [ { &quot;offer_id&quot;: &quot;3142&quot;, &quot;type&quot;: &quot;aio&quot;, &quot;flags&quot;: { &quot;d&quot;: 1, &quot;x&quot;: false, &quot;ne&quot;: -1 } }, .
      
    </div>
  </div>
  
  <div>
    <h2><a href="https://checkking.github.io/post/nginx/nginx6/">nginx so_reuseport</a></h2>
    <div class="post-style">
      
    </div>
  </div>
  
  <div>
    <h2><a href="https://checkking.github.io/post/nginx/nginx5/">为什么nginx默认使用ET模式的epoll</a></h2>
    <div class="post-style">
      
    </div>
  </div>
  
  <div>
    <h2><a href="https://checkking.github.io/post/arch/nginx_event_module/">nginx事件模块分析</a></h2>
    <div class="post-style">
      
      整体流程分析 先列出event模块相关定义的:
static ngx_command_t ngx_events_commands[] = { { ngx_string(&quot;events&quot;), NGX_MAIN_CONF|NGX_CONF_BLOCK|NGX_CONF_NOARGS, ngx_events_block, 0, 0, NULL }, ngx_null_command }; static ngx_core_module_t ngx_events_module_ctx = { ngx_string(&quot;events&quot;), NULL, ngx_event_init_conf }; ngx_module_t ngx_events_module = { NGX_MODULE_V1, &amp;ngx_events_module_ctx, /* module context <em>/ ngx_events_commands, /</em> module directives <em>/ NGX_CORE_MODULE, /</em> module type <em>/ NULL, /</em> init master <em>/ NULL, /</em> init module <em>/ NULL, /</em> init process <em>/ NULL, /</em> init thread <em>/ NULL, /</em> exit thread <em>/ NULL, /</em> exit process <em>/ NULL, /</em> exit master */ NGX_MODULE_V1_PADDING };  在ngx_init_cycle函数中，有下面部分代码:
      
    </div>
  </div>
  
  <div>
    <h2><a href="https://checkking.github.io/post/arch/nginx_probs1/">线上nginx错误日志追查</a></h2>
    <div class="post-style">
      
      问题描述 线上机器有一台机器报警，说摸个url请求失败率达到25%，等到线上机器查看nginx错误日志，发现下面的滚屏；
2017/04/10 18:00:28 [alert] 2378#0: *35137710183 socket() failed (24: Too many open files) while connecting to upstream, client: 202.69.12.16, server: api.mobojoy.baidu.com, request: &quot;GET /index.php?r=adfb/list&amp;al=847dd82e152ec6ddeb104ba8439a684d&amp;l=06e298ac92c301027067eea9a540dff4&amp;p=48cfe1bbaabf62b82e4f979f4cbeb44f&amp;hp=com.dianxinos.dxbs&amp;lc=xiaobu_yz_gl_PRE_FREE&amp;sdk=49 HTTP/1.1&quot;, upstream: &quot;fastcgi://127.0.0.1:9000&quot;, host: &quot;&mdash;-&quot; 2017/04/10 18:00:29 [crit] 2378#0: accept4() failed (24: Too many open files)  并且查看各个进程占用fd的情况：
$ lsof -n|awk &lsquo;{print $2}&rsquo;|sort|uniq -c|sort -nr|more 10259 2378 7520 16505 4273 5091 2661 5098 2508 5093 2201 5084 2183 5089 2001 5117 1934 5095 1927 5105 1911 5108 1906 5104 1809 5100 1713 5082 1631 5106 1336 5102  第一列为占用fd数，第二列为进程id，第一行就是nginx进程.
      
    </div>
  </div>
  
  <div>
    <h2><a href="https://checkking.github.io/post/cs/rpc_load_balance/">Locality-aware load balancing</a></h2>
    <div class="post-style">
      
      概述 LALB全称Locality-aware load balancing，是一个能把请求及时、自动地送到延时最低的下游的负载均衡算法，特别适合混合部署环境。 LALB可以解决的问题： - 下游的机器配置不同，访问延时不同，round-robin和随机分流效果不佳。 - 下游服务和离线服务或其他服务混部，性能难以预测。 - 自动地把大部分流量送给同机部署的模块，当同机模块出问题时，再跨机器。 - 优先访问本机房服务，出问题时再跨机房。
背景 最常见的分流算法是round robin和随机。这两个方法的前提是下游的机器和网络都是类似的，但在目前的线上环境下，特别是混部的产品线中，已经很难成立，因为： - 每台机器运行着不同的程序组合，并伴随着一些离线任务，机器的可用资源在持续动态地变化着。 - 机器配置不同。 - 网络延时不同。
这些问题其实一直有，但往往被OP辛勤的机器监控和替换给隐藏了。框架层面也有过一些努力，比如我厂UB框架中的WeightedStrategy是根据下游的cpu占用率来进行分流，但明显地它解决不了延时相关的问题，甚至cpu的问题也解决不了：因为它被实现为定期reload一个权值列表，可想而知更新频率高不了，等到负载均衡反应过来，一大堆请求可能都超时了。并且这儿有个数学问题：怎么把cpu占用率转为权值。假设下游差异仅仅由同机运行的其他程序导致，机器配置和网络完全相同，两台机器权值之比是cpu idle之比吗？假如是的，当我们以这个比例给两台机器分流之后，它们的cpu idle应该会更接近对吧？而这会导致我们的分流比例也变得接近，从而使两台机器的cpu idle又出现差距。你注意到这个悖论了吗？这些因素使得这类算法的实际效果和那两个基本算法没什么差距，甚至更差，用者甚少。
我们需要一个能自适应下游负载、规避慢节点的通用分流算法。
Locality-aware Locality-aware load balancing，能根据下游节点的负载分配流量，还能快速规避失效的节点，在很大程度上，这种算法的延时也是全局最优的。基本原理非常简单：
以下游节点的吞吐除以延时作为分流权值。  比如只有两台下游节点，W代表权值，QPS代表吞吐，L代表延时，那么W1 = QPS1 / L1和W2 = QPS2 / L2分别是这两个节点的分流权值，分流时随机数落入的权值区间就是流量的目的地了。
一种分析方法如下：
 稳定状态时的QPS显然和其分流权值W成正比，即W1 / W2 ≈ QPS1 / QPS2。 根据分流公式又有：W1 / W2 = QPS1 / QPS2 * (L2 / L1)。  故稳定状态时L1和L2应当是趋同的。当L1小于L2时，节点1会更获得相比其QPS1更大的W1，从而在未来获得更多的流量，直到其延时高于平均值或没有更多的流量。
注意这个算法并不是按照延时的比例来分流，不是说一个下游30ms，另一个60ms，它们的流量比例就是60 / 30。而是30ms的节点会一直获得流量直到它的延时高于60ms，或者没有更多流量了。以下图为例，曲线1和曲线2分别是节点1和节点2的延时与吞吐关系图，随着吞吐增大延时会逐渐升高，接近极限吞吐时，延时会飙升。左下的虚线标记了QPS=400时的延时，此时虽然节点1的延时有所上升，但还未高于节点2的基本延时（QPS=0时的延时），所以所有流量都会分给节点1，而不是按它们基本延时的比例（图中大约2:1）。当QPS继续上升达到1600时，分流比例会在两个节点延时相等时平衡，图中为9 : 7。很明显这个比例是高度非线性的，取决于不同曲线的组合，和单一指标的比例关系没有直接关联。在真实系统中，延时和吞吐的曲线也在动态变化着，分流比例更加动态。
      
    </div>
  </div>
  
  <div>
    <h2><a href="https://checkking.github.io/post/mind/tech_road/">读《技术人员的发展之路》之感</a></h2>
    <div class="post-style">
      
    </div>
  </div>
  
  <div>
    <h2><a href="https://checkking.github.io/post/cs/timer_keeping/">Timer Keeping</a></h2>
    <div class="post-style">
      
      在几点几分做某件事是RPC框架的基本需求，这件事比看上去难。
让我们先来看看系统提供了些什么： posix系统能以signal方式告知timer触发，不过signal逼迫我们使用全局变量，写async-signal-safe的函数，在面向用户的编程框架中，我们应当尽力避免使用signal。linux自2.6.27后能以fd方式通知timer触发，这个fd可以放到epoll中和传输数据的fd统一管理。唯一问题是：这是个系统调用，且我们不清楚它在多线程下的表现。
为什么这么关注timer的开销?让我们先来看一下RPC场景下一般是怎么使用timer的：
 在发起RPC过程中设定一个timer，在超时时间后取消还在等待中的RPC。几乎所有的RPC调用都有超时限制，都会设置这个timer。 RPC结束前删除timer。大部分RPC都由正常返回的response导致结束，timer很少触发。  你注意到了么，在RPC中timer更像是”保险机制”，在大部分情况下都不会发挥作用，自然地我们希望它的开销越小越好。一个几乎不触发的功能需要两次系统调用似乎并不理想。那在应用框架中一般是如何实现timer的呢？谈论这个问题需要区分“单线程”和“多线程”:
 在单线程框架中，比如以libevent, libev为代表的eventloop类库，或以GNU Pth, StateThreads为代表的coroutine / fiber类库中，一般是以小顶堆记录触发时间。epoll_wait前以堆顶的时间计算出参数timeout的值，如果在该时间内没有其他事件，epoll_wait也会醒来，从堆中弹出已超时的元素，调用相应的回调函数。整个框架周而复始地这么运转，timer的建立，等待，删除都发生在一个线程中。只要所有的回调都是非阻塞的，且逻辑不复杂，这套机制就能提供基本准确的timer。不过就像Threading Overview中说的那样，这不是RPC的场景。
 在多线程框架中，任何线程都可能被用户逻辑阻塞较长的时间，我们需要独立的线程实现timer，这种线程我们叫它TimerThread。一个非常自然的做法，就是使用用锁保护的小顶堆。当一个线程需要创建timer时，它先获得锁，然后把对应的时间插入堆，如果插入的元素成为了最早的，唤醒TimerThread。TimerThread中的逻辑和单线程类似，就是等着堆顶的元素超时，如果在等待过程中有更早的时间插入了，自己会被插入线程唤醒，而不会睡过头。这个方法的问题在于每个timer都需要竞争一把全局锁，操作一个全局小顶堆，就像在其他文章中反复谈到的那样，这会触发cache bouncing。同样数量的timer操作比单线程下的慢10倍是非常正常的，尴尬的是这些timer基本不触发。
  我们重点谈怎么解决多线程下的问题。
一个惯例思路是把timer的需求散列到多个TimerThread，但这对TimerThread效果不好。注意我们上面提及到了那个“制约因素”：一旦插入的元素是最早的，要唤醒TimerThread。假设TimerThread足够多，以至于每个timer都散列到独立的TImerThread，那么每次它都要唤醒那个TimerThread。 “唤醒”意味着触发linux的调度函数，触发上下文切换。在非常流畅的系统中，这个开销大约是3-5微秒，这可比抢锁和同步cache还慢。这个因素是提高TimerThread扩展性的一个难点。多个TimerThread减少了对单个小顶堆的竞争压力，但同时也引入了更多唤醒。
另一个难点是删除。一般用id指代一个Timer。通过这个id删除Timer有两种方式：1.抢锁，通过一个map查到对应timer在小顶堆中的位置，定点删除，这个map要和堆同步维护。2.通过id找到Timer的内存结构，做个标记，留待TimerThread自行发现和删除。第一种方法让插入逻辑更复杂了，删除也要抢锁，线程竞争更激烈。第二种方法在小顶堆内留了一大堆已删除的元素，让堆明显变大，插入和删除都变慢。
第三个难点是TimerThread不应该经常醒。一个极端是TimerThread永远醒着或以较高频率醒过来（比如每1ms醒一次），这样插入timer的线程就不用负责唤醒了，然后我们把插入请求散列到多个堆降低竞争，问题看似解决了。但事实上这个方案提供的timer精度较差，一般高于2ms。你得想这个TimerThread怎么写逻辑，它是没法按堆顶元素的时间等待的，由于插入线程不唤醒，一旦有更早的元素插入，TimerThread就会睡过头。它唯一能做的是睡眠固定的时间，但这和现代OS scheduler的假设冲突：频繁sleep的线程的优先级最低。在linux下的结果就是，即使只sleep很短的时间，最终醒过来也可能超过2ms，因为在OS看来，这个线程不重要。一个高精度的TimerThread有唤醒机制，而不是定期醒。
另外，更并发的数据结构也难以奏效，感兴趣的同学可以去搜索&rdquo;concurrent priority queue&rdquo;或&rdquo;concurrent skip list&rdquo;，这些数据结构一般假设插入的数值较为散开，所以可以同时修改结构内的不同部分。但这在RPC场景中也不成立，相互竞争的线程设定的时间往往聚集在同一个区域，因为程序的超时大都是一个值，加上当前时间后都差不多。
这些因素让TimerThread的设计相当棘手。由于大部分用户的qps较低，不足以明显暴露这个扩展性问题，在r31791前我们一直沿用“用一把锁保护的TimerThread”。TimerThread是baidu-rpc在默认配置下唯一的高频竞争点，这个问题是我们一直清楚的技术债。随着baidu-rpc在高qps系统中应用越来越多，是时候解决这个问题了。r31791后的TimerThread解决了上述三个难点，timer操作几乎对RPC性能没有影响，我们先看下性能差异。
那新TimerThread是如何做到的？
 一个TimerThread而不是多个。 创建的timer散列到多个Bucket以降低线程间的竞争，默认12个Bucket。 Bucket内不使用小顶堆管理时间，而是链表 + nearest_run_time字段，当插入的时间早于nearest_run_time时覆盖这个字段，之后去和全局nearest_run_time（和Bucket的nearest_run_time不同）比较，如果也早于这个时间，修改并唤醒TimerThread。链表节点在锁外使用ResourcePool分配。 删除时通过id直接定位到timer内存结构，修改一个标志，timer结构总是由TimerThread释放。 TimerThread被唤醒后首先把全局nearest_run_time设置为几乎无限大(max of int64)，然后取出所有Bucket内的链表，并把Bucket的nearest_run_time设置为几乎无限大(max of int64)。TimerThread把未删除的timer插入小顶堆中维护，这个堆就它一个线程用。在每次运行回调或准备睡眠前都会检查全局nearest_run_time， 如果全局更早，说明有更早的时间加入了，重复这个过程。  这里勾勒了TimerThread的大致工作原理，工程实现中还有不少细节问题，具体请阅读timer_thread.h和timer_thread.cpp。
struct TimerThreadOptions { // Scheduling requests are hashed into different bucket to improve // scalability. However bigger num_buckets may NOT result in more scalable // schedule() because bigger values also make each buckets more sparse // and more likely to lock the global mutex.
      
    </div>
  </div>
  

</div>
<div class="page_footer">
	<p>&copy; Check King 2018. Powered by <a href="http://gohugo.io/">Hugo</a> and <a href="https://github.com/jhu247/minimal-academic">Minimal Academic</a>.</p>
</div>
    
    


  </body>
</html>
