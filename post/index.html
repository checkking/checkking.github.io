<!DOCTYPE html>
<html lang="en-us">
<head>
  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  
  <meta name="generator" content="Hugo 0.49" />
  <meta name="author" content="Check King">

  
  <link rel="stylesheet" href="//cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.min.css">
  <link rel="stylesheet" href="//fonts.googleapis.com/css?family=Merriweather:400,700%7cOpen&#43;Sans:400,400italic,700%7cRoboto&#43;Mono%25!%28EXTRA%20*hugolib.PageOutput=Page%28/post%29%29">
  <link rel="stylesheet" href="/styles.css">
  

  

  
  <link rel="alternate" href="https://checkking.github.io/post/index.xml" type="application/rss+xml" title="Check King&#39;s Blog">
  <link rel="feed" href="https://checkking.github.io/post/index.xml" type="application/rss+xml" title="Check King&#39;s Blog">
  

  <link rel="apple-touch-icon" sizes="180x180" href="/img/favicon/apple-touch-icon.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/img/favicon/favicon-32x32.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/img/favicon/favicon-16x16.png">
  <link rel="manifest" href="/img/favicon/site.webmanifest">
  <link rel="mask-icon" href="/safari-pinned-tab.svg" color="#5bbad5">
  <meta name="msapplication-TileColor" content="#da532c">
  <meta name="theme-color" content="#ffffff">

  <link rel="manifest" href="/site.webmanifest">
  <link rel="icon" type="image/png" href="/img/icon.png">
  <link rel="apple-touch-icon" type="image/png" href="/img/icon-192.png">

  <link rel="canonical" href="https://checkking.github.io/post/">

  <meta property="twitter:card" content="summary_large_image">
  
  <meta property="twitter:site" content="@">
  <meta property="twitter:creator" content="@">
  
  <meta property="og:site_name" content="Check King&#39;s Blog">
  <meta property="og:url" content="https://checkking.github.io/post/">
  <meta property="og:title" content="Posts | Check King&#39;s Blog">
  <meta property="og:locale" content="en-us">
  
  <meta property="og:updated_time" content="2018-11-05T13:46:09&#43;08:00">
  

  <title>Posts | Check King&#39;s Blog</title>

  

</head>
<body>

<style type="text/css">

.masthead-hero {
  background-image: url("https://checkking.github.io/img/hero.jpg");
}
</style>

<div class="masthead-hero"></div>


  <h1>Posts</h1>

  

  
  
  <div>
    <h2><a href="https://checkking.github.io/post/arch/websocket/">Websocket协议总结</a></h2>
    <div class="post-style">
      
      ###概述 WebSocket协议被设计来取代现有的使用HTTP作为传输层的双向通信技术，并受益于现有的基础设施（代理、过滤、身份验证）。协议有两部分：握手和数据传输。 来自客户端的握手看起来像如下形式：
GET /chat HTTP/1.1 Host: server.example.com Upgrade: websocket Connection: Upgrade Sec-WebSocket-Key: dGhlIHNhbXBsZSBub25jZQ== Origin: <a href="http://example.com" target="_blank">http://example.com</a> Sec-WebSocket-Protocol: chat, superchat Sec-WebSocket-Version: 13  重点请求首部意义如下： * Connection: Upgrade：表示要升级协议 * Upgrade: websocket：表示要升级到 websocket 协议。 * Sec-WebSocket-Version: 13：表示 websocket 的版本。如果服务端不支持该版本，需要返回一个 Sec-WebSocket-Versionheader ，里面包含服务端支持的版本号。 * Sec-WebSocket-Key：与后面服务端响应首部的 Sec-WebSocket-Accept 是配套的，提供基本的防护，比如恶意的连接，或者无意的连接。
来自服务器的握手看起来像如下形式：
HTTP/1.1 101 Switching Protocols Upgrade: websocket Connection: Upgrade Sec-WebSocket-Accept: s3pPLMBiTxaQ9kYGzzhZRbK+xOo= Sec-WebSocket-Protocol: chat   Sec-WebSocket-Accept 根据客户端请求首部的 Sec-WebSocket-Key 计算出来。 计算公式为：  toBase64(sha1(Sec-WebSocket-Key + 258EAFA5-E914-47DA-95CA-C5AB0DC85B11))   一旦客户端和服务器都发送了它们的握手，且如果握手成功，接着开始数据传输部分。 这是一个每一端都可以的双向通信信道，彼此独立，随意发生数据。
      
    </div>
  </div>
  
  <div>
    <h2><a href="https://checkking.github.io/post/arch/frontier/">阅读长链接服务架构总结</a></h2>
    <div class="post-style">
      
      背景 目前项目中用到了公司的长链接服务，抽空研究了一下公司长链接服务源码。 如果没有长链接服务，一些消息推送等功能只能用短链接轮询，或者长链接轮询的方式。长链接能够很好的解决短轮询和长轮询的一些不足。
整体架构 !架构图
数据流交互 !数据流交互
 客户端传送fpid, aid, device_id, access_key等参数与grontier建立websocket连接， websocket 的subprotocol为pbbp2。 grontier维护webscoket连接池, 维护在内存中。 grontier向backbone注册映射, backbone将注册关系存入redis中。 客户端发送业务消息到grontier，grontier根据路由service, method参数进行路由调用backservice, backservice处理业务逻辑，将下行消息通过调用backbone接口返回，backbone将下行消息返回给grontier, 最终由grontier 返回给客户端。  源码分析 grontier/main.go 主要是启动两个server, 一个是thrift server, 一个是websocket server， 端口不一样。 其中thrift server对是用于与backbone和backservice交互的, websocket server是与客户端交互的。 rontier/thrift.go grontierThriftServer主要有3个函数，一个Start, 一个Close和handle。 Start是启动一个tcp监听端口，等待连接，如果有链接请求来了，则起一个协程调用handle处理这个链接。 handle 函数首先创建一个grontierServerhandler h，然后调用h.Serve，并传入BufferReader r, BufferWriter w。 在grontierServerHandler中，Serve函数循环从r中读取数据包，首先读取MessageHeader，包括messageType (int32)，name(string)，seq(int32)。其中name目前支持&rdquo;PushByUUID&rdquo; , messageType只支持CALL 。 读取正确的messageHeader后读取参数grontierPushByUUIDArgs。 读取完整的请求后，向request channel 塞入一条记录。 Serve函数还启动了一个协程，遍历channel 中的请求(request)， 调用grontierHandler的PushByUUID函数，也就是调用grontierClient的PushByUUID接口（是业务应用调用grontier对外提供的接口吗？还是backbone调用grontier?） Close是关闭tcp链接， 是在服务被shutdown的时候调用的。
grontier/grontier.go grontierWebsocketServer的结构体定义如下：
type grontierWebsocketServer struct { mu sync.Mutex listeners []net.
      
    </div>
  </div>
  
  <div>
    <h2><a href="https://checkking.github.io/post/lang/go1/">Golang defer return 返回值执行顺序总结</a></h2>
    <div class="post-style">
      
      背景 项目中遇到一个小问题，我用到一个库，但是这个库在异常情况下内部会panic，虽然可以在最外层的函数recover住，让服务继续运行，但业务上需要如果这个库panic了，能够做一些逻辑处理，也就是类似java等语言的try&hellip;cache操作。
方案 新加一个函数对库函数进行包装，然后recover住panic，并且调用的地方能够感知到出错了。打算在将recover返回的error信息返回给调用函数。因此做了如下改造：
func (r *Request) ReplyRunOnceDataV2(statuscode int, contentType string, data []byte) (err interface{}) { defer func() { err = recover() }() r.ReplyRunOnceData(statuscode, contentType, data) return }  注意，这里函数返回值定义了一个有名返回值，是基于如下golang基础知识：
1. 多个defer的执行顺序为“后进先出”； 2. 所有函数在执行RET返回指令之前，都会先检查是否存在defer语句，若存在则先逆序调用defer语句进行收尾工作再退出返回； 3. 匿名返回值是在return执行时被声明，有名返回值则是在函数声明的同时被声明，因此在defer语句中只能访问有名返回值，而不能直接访问匿名返回值； 4. return其实应该包含前后两个步骤：第一步是给返回值赋值（若为有名返回值则直接赋值，若为匿名返回值则先声明再赋值）；第二步是调用RET返回指令并传入返回值，而RET则会检查defer是否存在，若存在就先逆序插播defer语句，最后RET携带返回值退出函数；  因此，‍‍defer、return、返回值三者的执行顺序应该是：return最先给返回值赋值；接着defer开始执行一些收尾工作；最后RET指令携带返回值退出函数。
匿名返回值的情况 package main import ( &quot;fmt&quot; ) func main() { fmt.Println(&quot;a return:&quot;, a()) // 打印结果为 a return: 0 } func a() int { var i int defer func() { i++ fmt.
      
    </div>
  </div>
  
  <div>
    <h2><a href="https://checkking.github.io/post/arch/cas/">使用CAS解决一个业务问题</a></h2>
    <div class="post-style">
      
      问题描述 最近项目遇到这样一个问题，有一个用mysql数据库表模拟的任务队列，生产者会往表中增加任务，消费者采用轮询的方式去获取任务。其中新加入的任务的状态为NEW(1)，当任务被拿走并处于计算中的状态为PENDING(2)，当任务处理成功的状态为SUCCESS(0)，当任务被处理失败的状态为FAILED(3)。消费者从轮询数据库，如果有NEW状态的任务，拿到任务，则修改状态为PENDING。问题是，有多个消费者同时去查询数据库表，并更新表项，存在并发问题。
初步解决 对于数据库并发问题，一个直觉的做法就是采用加锁的办法，因此采用下面这种方式实现:
tx := db.Begin() tx = tx.Raw(&quot;SELECT * FROM parser_job WHERE id=? FOR UPDATE&quot;, job.Id).Scan(&amp;job) if tx.RecordNotFound() { tx.Rollback() return nil, nil } if tx.Error != nil { logs.Errorf(&quot;DequeJob db query failed, err:%s&quot;, tx.Error.Error()) tx.Rollback() return nil, errors.New(tx.Error.Error()) } columns := make(map[string]interface{}, 0) columns[&quot;status&quot;] = common.STATUS_PENDING err := tx.Exec(&quot;UPDATE parser_job SET status=? WHERE id=?&quot;, common.STATUS_PENDING, job.Id).Error if err != nil { logs.Errorf(&quot;DequeJob db update failed, err:%s&quot;, err.
      
    </div>
  </div>
  
  <div>
    <h2><a href="https://checkking.github.io/post/nginx/nginx8/">nginx配置管理源码解析</a></h2>
    <div class="post-style">
      
      一个典型的nginx.conf配置 worker_processes 1; events { worker_connections 1024; } http { include mime.types; default_type application/octet-stream; log_format main &lsquo;$remote_addr - $remote_user [$time_local] &quot;$request&quot; &lsquo; &lsquo;$status $body_bytes_sent $request_id &quot;$http_referer&quot; &lsquo; &lsquo;&quot;$http_user_agent&quot; &quot;$http_x_forwarded_for&quot;&rsquo;; access_log logs/access.log main; sendfile on; #tcp_nopush on; #keepalive_timeout 0; keepalive_timeout 65; #gzip on; server { listen 80; server_name www.domain.com; root /root/com/domain/www; index index.html index.htm index.php; location ~ .(jpg|png|gif|js|css|swf|flv|ico)$ { expires 12h; } #charset koi8-r; access_log logs/host.access.log main; error_log logs/host.error.log debug; location / { if (!
      
    </div>
  </div>
  
  <div>
    <h2><a href="https://checkking.github.io/post/lang/cpp4/">为什么析构函数不能抛出异常</a></h2>
    <div class="post-style">
      
    </div>
  </div>
  
  <div>
    <h2><a href="https://checkking.github.io/post/lang/cpp5/">阅读笔记-线程安全的对象生命周期管理</a></h2>
    <div class="post-style">
      
      避免使用原始指针，最佳实践是shared_ptr和weak_ptr的结合。因为原始指针容易造成空悬指针/野指针(因为在一个线程里调用一个对象，这个对象可能在其他的线程里被销毁了)， shared_ptr通过引用计数的方式保证有线程引用对象的时候，对象不会被销毁，weak_ptr的引入可以避免shared_ptr带来的延长对象生命周期的问题。
 用enable_shared_ptr可以避免回调函数注册时传入的对象指针this，在回调的时候变成野指针（boost::bind传入this作为当前对象，但是在回调的时候，this可能被销毁了）
 前台线程读(多个，高并发), 后台线程写（少量，低频）
  可以用互斥锁来解决这个问题， shared_ptr存放Map，shared_ptr.swap()实现copy on write
class CustomerData : boost::noncopyable { public: CustomerData() : _data(new Map) { } int query(const string&amp; customer, const string&amp; stock) const { MapPtr data = getData(); Map::const_iterator entries = data-&gt;find(customer); if (entries != data-&gt;end()) { return findEntry(entries-&gt;second, stock); } else { return -1; } } void update(const string&amp; customer, const EntryList&amp; entries) { MutexLockGuard lock(_mutex); if (!
      
    </div>
  </div>
  
  <div>
    <h2><a href="https://checkking.github.io/post/arch/rate_limitator/">接口流量控制</a></h2>
    <div class="post-style">
      
      背景 公有云的服务通常是将私有云的服务进行包装，并对外提供服务的，由于业务应用系统的负载能力有限，为了防止非预期的请求对系统压力过大而拖垮业务应用系统，需要对请求流量进行限速。
漏斗算法 漏桶(Leaky Bucket)算法思路很简单,水(请求)先进入到漏桶里,漏桶以一定的速度出水(接口有响应速率),当水流入速度过大会直接溢出(访问频率超过接口响应速率),然后就拒绝请求,可以看出漏桶算法能强行限制数据的传输速率。
 优点  可以让流量匀速通过，实现简单
 缺点  流量始终匀速输出，对于突发特性的流量支持地不好
 实现  用一个队列即可搞定，消费者线程匀速取出
令牌桶算法 令牌桶算法(Token Bucket)和 Leaky Bucket 效果一样但方向相反的算法,更加容易理解.随着时间流逝,系统会按恒定1/QPS时间间隔(如果QPS=100,则间隔是10ms)往桶里加入Token(想象和漏洞漏水相反,有个水龙头在不断的加水),如果桶已经满了就不再加了.新请求来临时,会各自拿走一个Token,如果没有Token可拿了就阻塞或者拒绝服务.
 优点  可以应对突发性的流量
 缺点  实现起来不是很容易
 实现  下面详细
通过redis实现令牌桶算法进行流量控制 流量控制项目  单个Ip访问速度限制  规则: reqs / seconds， 例如: 300 / 60, 表示每分钟最多允许300个请求，也就是平均每秒钟5个请求，但是我们可以允许流量的抖动，允许每5秒内有100个请求，这时，我们可以这样设定： 100 / 5, 两个规则加在一起就能满足两个要求了。
具体流程：
一个请求过来，对于每个规则构造key:
key = GLOBAL_PREFIX_FOR_REDIS + PREFIX_RATE_LIMIT + KEY_SPLIT_FLAG + request.getClientIp() + i;   判断redis中key对应的列表长度, 如果列表长度小于限制，则通过; 如果大于等于限制，首先判断最早加入列表的元素（time）时间和当前时间差是否大于perSecond， 如果是，则将最早的时间元素从redis中移除，并将当前时间元素加入redis，允许请求通过，而且标记上后续清理过期的时间项目。如果不允许通过，则抛出异常  // 统计是否封禁 for (int i = 0; maxRateLimitPerIps !
      
    </div>
  </div>
  
  <div>
    <h2><a href="https://checkking.github.io/post/arch/sample/">谈谈抽样试验</a></h2>
    <div class="post-style">
      
      背景 对于一些重要的产品，开发出的新功能往往需要真实流量进行验证才能知道这个功能带来的收益是好还是坏，比如图搜变现的策略rd想要在图搜wise端出游戏的一个广告banner，点击这个广告banner，会跳到一个下载中间页，我们最终的目的是要提高下载量，这就要评估一下哪种下载中间页会提高下载量，当然还有一些其他的评估指标。因此需要从整个流量中抽取两个小部分流量来做对比实验。怎么去分配流量，让不同流量走不同的逻辑就是抽样框架的主要任务。 还有FE开发了一种新的广告样式，需要确认这种样式会不会提高CTR。这些新策略，新样式的上线，都需要灰度发布，也就是小流量实验。
我们的广告模块也实现了一个实验框架，用于灰度发布，我分析一下这个实验框架的细节。
实验框架的整体流程 实验用户通过抽样平台上创建抽样试验，比如这个抽样试验要对流量按照uid进行划分，实验组需要流量为1%, 对照组所需流量为1%，如果现有所有流量层有按照cuid划分的，并且这一层上剩余流量充足，则在这一层上选取流量区间分配给实验组和对照组。
则可以将流量区间1000~1099分配给实验组，并创建一个新的sid加入配置，将1100~1199分配给对照组，并创建一个新的sid加入配置。
流量分配好之后，就可以在这个流量下面创建一些策略变量，比如在实验组中这个变量值为x,在对照组中，这个变量值为y（变量需要指定模块）。还可以加入一些过滤条件，对流量进行过滤。比如比如query不能在某个此表中。
实验创建好，并通过审核，准备上线。就会生成两类配置。一类是广告入口模块（midway）所使用的流量划分配置，模块根据这个配置，对请求打上sid列表。传递给下游模块。另外一类配置是各个模块使用的抽样变量配置。程序在运行的时候根据不同sid取得不同的变量值，走不同的逻辑。
配置是通过一个配置配送模块进行的, 各个模块热加载配置。
具体打sid的过程 midway拿到流量分配配置后，解析配置，layermanager将按层解析配置，按层管理各个layer, layer中包含各个抽样节点，比如sid 999的流量区间为start=0, end=999
而且每层的sid都是按照start排序的。后续一个请求hash得到的一个整数就可以按照二分查找。
一个请求过来之后，就会一层一层地去匹配sid，每层最多匹配一个。
查找变量过程 下游模块加载抽样变量配置，热加载，按照变量名组织:
struct SampleParam { uint32_t sid,; void* val; } std::unordered_map&lt;std::string, SampleParam&gt; sample_variables.  当代码要用到抽样变量时，先到sample_variable中查找，如果不到，则用默认值。
为了统计和评估，在日志中加入sid, 这样可以统计pv,ctr等信息。
流量切分 流量划分的粒度为0.1%， 我们将全部流量划分成10000等份，这样全部流量就是0~9999。对输入进行随机hash计算，可以将流量打散在全流量中。 流量可以按照以下几种方式来划分： 1) 按IP来进行划分(地域)  2) 按UID进行划分 3) 按cookie进行划分 4) 按query进行划分
首先将key对应的字符串用creat_sign_murmur64函数转成64位的整数，然后对10000取模，得到一个0~10000之间的整数。整个整数再去和各个抽样进行匹配，如果在某个抽样区间，则将请求打上对应的sid。
实现流量的分层 100%的流量很容易被用完，加入每个实验都需要10%的流量，这样同时只能做10个实验。而且有些实验要求更多的流量，比如有些实验要求在特定query下才走什么要的策略，假如只抽取1%的流量，这样再用这个流量进行query过滤，那就太少了，因此这类实验往往要求很多的流量，比如30%。这样势必会造成流量不够用的情况。
因此需要进行流量分层，将100%的流量正交成16个全流量，从逻辑上将实验流量变成原来的16倍。正交的意思是指第一层的某段很小的1%流量能够均匀地分散到其他层的100%上，而不是集中在其他层的某一段。 正交层之间几乎没有相互影响：
假如有实验1，有实验组exp_a和对照组control_a，各占流量1%,在第一层，第二层中有实验2，有实验组exp_a，占流量2%。如果不正交的话，导致实验1和实验2流量重叠，一个请求要么全部中实验一和实验二，要么全不中。这样两个实验就可能会相互影响了（即使两个实验不互斥）。如果保证正交的话，第一层实验1的流量均匀的落到第二层，这样就只有极少一部分流量落到实验2中的流量。
如果实验1和实验2互斥，比如都要在一个广告位上出广告，这样实验一和实验二必须都在同一层。
分层的实现是为不同层的creat_sign_murmur64函数设置不同的初始化种子字符串实现的，在创建层的时候为每个层分配一个全局唯一的id，作为层的初始化seed。具体代码如下：
ErrorCode calc_sample_ratio(const boost::any &amp;any_value, const std::string &amp;seed, double &amp;sample_ratio) { std::string val; if (boost_any_to_str(any_value, val) !
      
    </div>
  </div>
  
  <div>
    <h2><a href="https://checkking.github.io/post/cs/link/">硬连接和软连接</a></h2>
    <div class="post-style">
      
      背景 项目的nginx日志太多了，需要迁移到其他磁盘，另外一个同学采用软链的方式迁移到其他磁盘上，这样不影响现有程序。对于软链和硬连接概念上还是有些模糊，所以总结一下，直接抄Quora上的一个通俗的回答.
What is the difference between a hard link and a soft link? Have you ever given a thought to what happens when you store a file on your hard disk?
I will show you.
Let’s create a file first.
touch myfile cat &gt; myfile Hello, world!  cat file should display this text:
cat myfile Hello, world!  Where do you think myfile is stored?
An obvious and correct answer is your hard drive.
      
    </div>
  </div>
  

</div>
<div class="page_footer">
	<p>&copy; Check King 2018. Powered by <a href="http://gohugo.io/">Hugo</a> and <a href="https://github.com/jhu247/minimal-academic">Minimal Academic</a>.</p>
</div>
    
    


  </body>
</html>
